{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP3SihOBVKd24nfjRBs0VQJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "ir",
      "display_name": "R"
    },
    "language_info": {
      "name": "R"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nicklausmillican/StatisticalRethinkingIISolutions/blob/main/StatisticalRethinkingSolutions2_Ch7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chapter 7"
      ],
      "metadata": {
        "id": "TX44yv15HT9X"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1JPYvU_ERsQ-"
      },
      "outputs": [],
      "source": [
        "install.packages(c(\"coda\",\"mvtnorm\",\"devtools\",\"loo\",\"dagitty\"))\n",
        "devtools::install_github(\"rmcelreath/rethinking@slim\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "library(rethinking)"
      ],
      "metadata": {
        "id": "FFONo5eeR7ir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Easy"
      ],
      "metadata": {
        "id": "pJvvqpdCSIOj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7E1\n",
        "#### Question\n",
        "State the three motivating criteria that define information entropy. Try to express each in your  own words.\n",
        "\n",
        "#### Answer\n",
        "Entropy is a measure of uncertainty; information resolves that uncertainty (e.g., with evidence).  So entropy *feels* a bit like probability in that both deal with levels of (un)certainty.  It shouldn't be surprising, then, that entropy H is a function of probability.\n",
        "\n",
        "$$H(X) = \\sum_{i=1}^n p(X=x_i) \\times log_b(\\frac{1}{p(X=x_i)})$$\n",
        "$$= - \\sum_{i=1}^n p(X=x_i) \\times log_b(p(X=x_i))$$\n",
        "$$= -E[log_b(p(X=x_i))]$$\n",
        "\n",
        "How to interpret?  Think of $log_b(\\frac{1}{p(X=x_i)})$ as \"surprise\": the greater the probability $p(X=x_i)$, the less surprising it is when that event occurs; conversely, the less probable an event $p(X=x_i)$, the more surprising it is when it occurs.  Next, we *weight* the probability of each event $p(X=x_i)$ by its probability of occuring $p(X=x_i)$ and sum over each event $X=x_i$.  This gives us a *weighted average* of surprise for $X$.  We actually use the $log$ of $\\frac{1}{p(X=x_i)}$ in order to achieve a few desirable traits for our measure of uncertainty.\n",
        "\n",
        "From p. 205:\n",
        "1.   **Continuity:** Just as we want our (un)certainty to be able to slide smoothly from completely uncertain to completely certain, we want informational entropy to do the same.  Probability accomplishes this and, as a function of probability, the formula for $H$ permits the same.\n",
        "2.   **Proportionality:** All else being equal, more potential outcomes for $X$ should increase our uncertainty about $X$.  You can see how the formula for $H$ accomplishes this.  If instead of being, say, 3 values for $X$ there are 4, $H$ becomes the sum of 4 terms instead of only 3; plus, the additional 4th value for $X$ means that the probability of each possible value has probably decreased--thus increasing the surprise for each.  All told, $H$ increases.\n",
        "3.   **Additivity:** If we have two events about which we are uncertain, it is desirable to say that our total uncertainty is the sum of those events.  Similarly for more events.  The formula for $H$ accomplishes this by the $\\sum$ operator.  We sum the surprise, weighted by its probability of happening, of each possible event.\n",
        "\n",
        "Additionally, there are some other important features of information entropy no mentioned in the book:\n",
        "4.   **Non-Negativity:** We cannot be negatively uncertain about an event; we can only be completely certain--which is 0 uncertainty.  The formula for $H$ accomplishes this by its use of probabilities: probabilities also cannot be negative.\n",
        "5.   **Maximal Value:** Just as there is a minimal entropy (0), there is a maximal entropy.  Maximal entropy occurs when each possible value are equally likely.  You can see this in the formula for $H$: if the probability of any event becomes greater than $\\frac{1}{n}$, then the probabilities of other events must decrease...increasing their surprise.  This results in less overall entropy.\n",
        "\n",
        "> This chapter addresses a concept called \"MaxEnt\" or \"maximal entropy\".  This is a similar concept, but it refers to the maximal entropy of a variable under some set of contraints.\n",
        "\n",
        "There are many other features of informational entropy that we could list.  But we'll stop here.\n",
        "\n",
        "If you're interested in a deeper but still-understandable resource on information theory, I suggest [Probability and Information: An Integrated Approach 2nd Edition](https://www.amazon.com/Probability-Information-Integrated-David-Applebaum/dp/0521899044) and [Information Theory: A Tutorial Introduction (2nd Edition)](https://www.amazon.com/Information-Theory-Tutorial-Introduction-2nd/dp/1739672704/ref=sr_1_1?crid=QB4WC07L2QV2&dib=eyJ2IjoiMSJ9.HdyNIMnteFZLf7Ghuh6b4KpfMMBis3Cg2Cn4pOhcL08uhNjOVjY5qqMtASytMwiCDZNo8atQ_BvoUOLSeLvzJMSkRrLHGJNdYa3VnLzWgodcgfMRGbJkHt5VFKslyyzX4JYNra34ExCHrvPo7sXCCkIN3NFpJom82G6K_FzCkaU-mOKz-PkQ3CnNhjkBzmYSdIkVdNUmWSE-Di1EjxG_4rWfCra_68Z8zvOI4yM1ub0uKR_QGV0xFv66L61PHlPS25GTH9hCAOTv5q0nezWOtHUX9fO6YEyj17fuskNrV5M.dpOwik_DNtNOYUJyMa8EC825qBdeL0uQJYgazlfU7l0&dib_tag=se&keywords=information+theory&qid=1709823456&s=books&sprefix=information+theory%2Cstripbooks%2C151&sr=1-1-spons&sp_csd=d2lkZ2V0TmFtZT1zcF9hdGY&psc=1)."
      ],
      "metadata": {
        "id": "nm9yt5lBSKk0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7E2-7E4\n",
        "#### Questions\n",
        "2.   Suppose a coin is weighted such that, when it is tossed and lands on a table, it comes up heads 70% of the time. What is the entropy of this coin?\n",
        "3.   Suppose a four-sided die is loaded such that, when tossed onto a table, it shows “1” 20%, “2”  25%, “3” 25%, and “4” 30% of the time. What is the entropy of this die?  \n",
        "4.   Suppose another four-sided die is loaded such that it never shows “4”. The other three sides show equally often. What is the entropy of this die?\n",
        "\n",
        "#### Answers\n",
        "We'll group these answers, since they all follow the same process.  We just need to define the probabilities given in the question, then implement our formula for entropy.\n",
        "\n",
        "For each, I'll calculate entropy in a few different ways, and also compare it to the maximal entropy for that situation described in the question.\n",
        "\n",
        "Finally, I simulate data according to the situation described in the problem, and then calculate the empirical entropy from that generated data, both manually and with the `entropy` package."
      ],
      "metadata": {
        "id": "TrV9l8W7ijB0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "install.packages(\"entropy\")\n",
        "library(entropy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VAw1GgxolpDm",
        "outputId": "0de01501-30e8-4d80-9950-b0738355ba43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 7E2\n",
        "***Suppose a coin is weighted such that, when it is tossed and lands on a table, it comes up heads 70% of the time. What is the entropy of this coin?***"
      ],
      "metadata": {
        "id": "zIYruu3Njrh8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "p <- c(0.7, 1-0.7)\n",
        "maxP <- c(0.5, 1-0.5)\n",
        "\n",
        "(H1 <- -sum(p*log(p)))\n",
        "(H2 <- sum(p*log(1/p)))\n",
        "\n",
        "(maxH1 <- -sum(maxP*log(maxP)))\n",
        "(maxH2 <- sum(maxP*log(1/maxP)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "rCIxw6cbkSHG",
        "outputId": "4c30b563-f8dd-4a84-f531-d16529c48a1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "0.610864302054894"
            ],
            "text/markdown": "0.610864302054894",
            "text/latex": "0.610864302054894",
            "text/plain": [
              "[1] 0.6108643"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "0.610864302054894"
            ],
            "text/markdown": "0.610864302054894",
            "text/latex": "0.610864302054894",
            "text/plain": [
              "[1] 0.6108643"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "0.693147180559945"
            ],
            "text/markdown": "0.693147180559945",
            "text/latex": "0.693147180559945",
            "text/plain": [
              "[1] 0.6931472"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "0.693147180559945"
            ],
            "text/markdown": "0.693147180559945",
            "text/latex": "0.693147180559945",
            "text/plain": [
              "[1] 0.6931472"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outcomes <- c(\"heads\", \"tails\")\n",
        "d <- sample(x=outcomes, size=100, replace=TRUE, prob=p)\n",
        "\n",
        "(empiricalP <- c(sum(d==\"heads\")/length(d), sum(d==\"tails\")/length(d)))\n",
        "\n",
        "(empiricalH <- -sum(empiricalP*log(empiricalP)))\n",
        "entropy(d) # entropy package"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "T7IM6BmDmSGF",
        "outputId": "89c81984-af2d-4d4c-fe7e-1c3dd8eeb063"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style>\n",
              ".list-inline {list-style: none; margin:0; padding: 0}\n",
              ".list-inline>li {display: inline-block}\n",
              ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
              "</style>\n",
              "<ol class=list-inline><li>0.62</li><li>0.38</li></ol>\n"
            ],
            "text/markdown": "1. 0.62\n2. 0.38\n\n\n",
            "text/latex": "\\begin{enumerate*}\n\\item 0.62\n\\item 0.38\n\\end{enumerate*}\n",
            "text/plain": [
              "[1] 0.62 0.38"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "0.664064126564108"
            ],
            "text/markdown": "0.664064126564108",
            "text/latex": "0.664064126564108",
            "text/plain": [
              "[1] 0.6640641"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "0.664064126564108"
            ],
            "text/markdown": "0.664064126564108",
            "text/latex": "0.664064126564108",
            "text/plain": [
              "[1] 0.6640641"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 7E3\n",
        "***Suppose a four-sided die is loaded such that, when tossed onto a table, it shows “1” 20%, “2” 25%, “3” 25%, and “4” 30% of the time. What is the entropy of this die?***"
      ],
      "metadata": {
        "id": "QoiYvV2Bpc3Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "p <- c(0.2, 0.25, 0.25, 0.3)\n",
        "maxP <- c(0.25, 0.25, 0.25, 0.25)\n",
        "\n",
        "(H1 <- -sum(p*log(p)))\n",
        "(H2 <- sum(p*log(1/p)))\n",
        "\n",
        "(maxH1 <- -sum(maxP*log(maxP)))\n",
        "(maxH2 <- sum(maxP*log(1/maxP)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "G2vVVYXnpjpe",
        "outputId": "2b180e30-6763-4782-9016-4d9de87affce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "1.37622660434455"
            ],
            "text/markdown": "1.37622660434455",
            "text/latex": "1.37622660434455",
            "text/plain": [
              "[1] 1.376227"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "1.37622660434455"
            ],
            "text/markdown": "1.37622660434455",
            "text/latex": "1.37622660434455",
            "text/plain": [
              "[1] 1.376227"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "1.38629436111989"
            ],
            "text/markdown": "1.38629436111989",
            "text/latex": "1.38629436111989",
            "text/plain": [
              "[1] 1.386294"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "1.38629436111989"
            ],
            "text/markdown": "1.38629436111989",
            "text/latex": "1.38629436111989",
            "text/plain": [
              "[1] 1.386294"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outcomes <- c(\"1\", \"2\", \"3\", \"4\")\n",
        "d <- sample(x=outcomes, size=100, replace=TRUE, prob=p)\n",
        "\n",
        "(empiricalP <- table(d)/length(d))\n",
        "\n",
        "(empiricalH <- -sum(empiricalP*log(empiricalP)))\n",
        "entropy(d) # entropy package"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "yx2rNU-hp0MK",
        "outputId": "127047b2-5189-4c70-fc94-e497466a8a28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "d\n",
              "   1    2    3    4 \n",
              "0.23 0.26 0.23 0.28 "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "1.38272048392604"
            ],
            "text/markdown": "1.38272048392604",
            "text/latex": "1.38272048392604",
            "text/plain": [
              "[1] 1.38272"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "1.38272048392604"
            ],
            "text/markdown": "1.38272048392604",
            "text/latex": "1.38272048392604",
            "text/plain": [
              "[1] 1.38272"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 7E5\n",
        "***Suppose another four-sided die is loaded such that it never shows “4”. The other three sides show equally often. What is the entropy of this die?***"
      ],
      "metadata": {
        "id": "hbk6FZHeqLjB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "p <- c(1/3, 1/3, 1/3)\n",
        "maxP <- c(0.25, 0.25, 0.25, 0.25)\n",
        "\n",
        "(H1 <- -sum(p*log(p)))\n",
        "(H2 <- sum(p*log(1/p)))\n",
        "\n",
        "(maxH1 <- -sum(maxP*log(maxP)))\n",
        "(maxH2 <- sum(maxP*log(1/maxP)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "f0c7b89c-0dd7-4c28-eb9f-c26747dae00d",
        "id": "qwsc_ozWqWwy"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "1.09861228866811"
            ],
            "text/markdown": "1.09861228866811",
            "text/latex": "1.09861228866811",
            "text/plain": [
              "[1] 1.098612"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "1.09861228866811"
            ],
            "text/markdown": "1.09861228866811",
            "text/latex": "1.09861228866811",
            "text/plain": [
              "[1] 1.098612"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "1.38629436111989"
            ],
            "text/markdown": "1.38629436111989",
            "text/latex": "1.38629436111989",
            "text/plain": [
              "[1] 1.386294"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "1.38629436111989"
            ],
            "text/markdown": "1.38629436111989",
            "text/latex": "1.38629436111989",
            "text/plain": [
              "[1] 1.386294"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outcomes <- c(\"1\", \"2\", \"3\")\n",
        "d <- sample(x=outcomes, size=100, replace=TRUE, prob=p)\n",
        "\n",
        "(empiricalP <- table(d)/length(d))\n",
        "\n",
        "(empiricalH <- -sum(empiricalP*log(empiricalP)))\n",
        "entropy(d) # entropy package"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "b04163a1-4d87-40cf-a1bb-697cedcc0e40",
        "id": "shDrT-2AqWw6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "d\n",
              "   1    2    3 \n",
              "0.31 0.33 0.36 "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "1.09671983946956"
            ],
            "text/markdown": "1.09671983946956",
            "text/latex": "1.09671983946956",
            "text/plain": [
              "[1] 1.09672"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "1.09671983946956"
            ],
            "text/markdown": "1.09671983946956",
            "text/latex": "1.09671983946956",
            "text/plain": [
              "[1] 1.09672"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Medium"
      ],
      "metadata": {
        "id": "TI-MQfNNqG8m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7M1\n",
        "Write down and compare the definitions of AIC and WAIC. Which of these criteria is most general? Which assumptions are required to transform the more general criterion into a less general one?\n",
        "\n",
        "#### Answer\n",
        "Let's start with WAIC.\n",
        "\n",
        "$$WAIC = -2(lppd_{WAIC} - P_{WAIC})$$\n",
        "\n",
        "where\n",
        "\n",
        "$$lppd_{WAIC} = \\sum_{i=1}^n log(E_\\theta[Pr(y_i | \\theta)])\n",
        "= \\sum_{i=1}^nlog(\\frac{1}{S} \\sum_s Pr(y_i | \\theta_s))$$\n",
        "\n",
        "is the ***log-pointwise-predictive-density*** for WAIC (with uppercase $S$ is the number of posterior draws, lowercase $s$ representing a single posterior draw, and $\\theta$ is the estimated posterior parameters from the draw of $s$) and\n",
        "\n",
        "$$P_{WAIC} = \\sum_{i=1}^n Var_\\theta[log(Pr(y_i | \\theta)]$$\n",
        "\n",
        "is the ***WAIC penalty term***, which takes the variance of each observation $y_i$ across all parameter estimates $\\theta$ from the posterior distribution, then sums them.  The penalty term will tend to be larger for models that are overfit since probability of any observation $y_i$ will change more across the different parameter estimates in the posterior.\n",
        "\n",
        "Now onto AIC (NOTE: McElreath uses a Bayesian AIC, which uses the posterior distribution.  This is unusual; most discussionss of AIC use a frequentist definition, using the maximum likelihood instead of the posterior).  The formula for AIC has a similar structure to that of WAIC:\n",
        "\n",
        "$$AIC = -2(lppd_{AIC} - P_{AIC})$$\n",
        "\n",
        "where\n",
        "\n",
        "$$lppd_{AIC} = \\sum_{i=1}^n log(Pr(y_i | \\theta_{MAP}))$$\n",
        "\n",
        "is the ***log-pointwise-predictive-density*** for AIC of the data, taken at the point value of $\\theta$ that maximizes the posterior, and\n",
        "\n",
        "$$P_{AIC} = \\#\\theta$$\n",
        "\n",
        "is the ***AIC penalty term***, which is just the number of parameters in the model.  The intuition here is that models with more parameters are more likely to overfit and should therefore incur a larger penalty.\n",
        "\n",
        "So the things that distinguish WAIC and AIC are:\n",
        "*   WAIC considers the entire posterior distribution; AIC considers only a single point, the value of $theta$ that maximizes the posterior.\n",
        "*   WAIC estimates a penalty based on variance of fit; AIC uses a asymptotic heuristic to assess overfitting.\n",
        "\n",
        "Thus, WAIC is more general that AIC.  \n",
        "\n",
        "The WAIC and AIC are similar with very large sample sizes.  In this case, maximum value of the posterior (MAP) is a good approximation for the posterior distribution because the spread of the posterior is minimized such that posterior piles tightly around the MAP.\n",
        "\n",
        "But that the posterior converges to the MAP is not exactly the reason that AIC and WAIC converge.  Instead, consider both as $n \\rightarrow \\infty$.\n",
        "\n",
        "$$WAIC_{n \\rightarrow \\infty}\n",
        "= -2(\\sum_{i=1}^{n=\\infty} log(E_\\theta[Pr(y_i | \\theta)]) - \\sum_{i=1}^{n=\\infty} Var_\\theta[log(Pr(y_i | \\theta)])\n",
        "= -2(\\infty - 0) = -\\infty$$\n",
        "\n",
        "$$AIC_{n \\rightarrow \\infty}\n",
        "= -2(\\sum_{i=1}^n log(Pr(y_i | \\theta_{MAP})) - \\# \\theta)\n",
        "= -2(\\infty - \\# \\theta) = -\\infty$$\n",
        "\n",
        "NOTE: As I mentioned above, McElreath uses a slightly unusual definition of AIC.  Usually, the AIC uses $\\theta_{MLE}$, which is the value of $\\theta$ that maximizes the likelihood, rather than $\\theta_{MAP}$.  But the take-home message is the same.  As $n \\rightarrow \\infty$, AIC and WAIC merge.  To see this in the MLE case, notice that the MLE and MAP converge as $n \\rightarrow \\infty$; they also tend to converge if a flat prior is used for the posterior estimates.  Then, the argument follows just the same."
      ],
      "metadata": {
        "id": "Lgo6wNS7qKC6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7M2\n",
        "Explain the difference between model selection and model comparison. What information is lost under model selection?\n",
        "\n",
        "#### Answer\n",
        "Both **model selection** and **model comparison** use methods such as *information criteria* (WAIC), *Pareto-smoothed importance sampling* (PSIS) or *cross validataion* (CV) to rank the models based on their expected performance with new data.  The difference is that model selection...well...selects the best-ranked model to interpret and report; conversely, model comparison retains for use each model.  There is a third option that is only briefly mentioned in this (2nd) edition of the book, but which is expanded upon in the previous (1st) edition: **model ensemble**, where the predictions of the various models are combined in proportion to their performance in WAIC/PSIS/CV.\n",
        "\n",
        "When we are concerned with making predictions, we're forced to use model ensemble or model selection.  After all, WAIC/PSIS/CV are meant to tell us how well our model is likely to <u>predict</u> unobserved cases.\n",
        "\n",
        "But if we're concerned with inference, we should use model comparison.  WAIC/PSIS/CV do NOT tell us about the causal validity of our model; thus, better scores do not mean more valid models.  Model selection and model ensemble can discard important information regarding the uncertainty of our our model selection.  For instance, if two models have similar claims to inferential validity, WAIC/PSIS/CV scores can help us determine which model is more likely overfitting the data and therefore less generalizable.\n",
        "\n",
        "Let's look at an example.  From the book (p.231), we use the `compare()` function get some PSIS outputs from several models.\n",
        "\n",
        "![image.png](data:image/png;base64,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)\n",
        "\n",
        "The PSIS scores are the left-most column; the models are listed from *best* PSIS score (top) to *worst* PSIS score (bottom).  In model selection, we would only use the top model `m5.1`.  In model ensemble, we would combine the prediction from each model, weigthing those prediction according to their corresponding value in the `weight` column (so `m5.1` and `m5.3` would get all of the weight).  In model comparison, we would report on each model.  By reporting on each model, and through some systematic testing, we could learn which variables may be more relevant to the system under study.  For instance, is models with explanatory variable X routinely score worse than models without X, we might suspect that X may not be highly relevant to our system."
      ],
      "metadata": {
        "id": "QGLI_D58MZ52"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7M3\n",
        "When comparing models with an information criterion, why must all models be fit to exactly the same observations? What would happen to the information criterion values, if the models were fit to different numbers of observations? Perform some experiments, if you are not sure.\n",
        "\n",
        "#### Answer\n",
        "The reason that models must be tested against the same data is almost too obvious to state: *Information criteria is used to assess the fit of a model to a particular set of data; in this way, we can compare models.  It would not make sense to compare the performance of one model on one set of set data to the performance of another model on a separate set of data*.\n",
        "\n",
        "Regarding the second part of the question, we should not compare the performance of one model on a set of data against the performance of another model on a subset of the same data because information criteria *sums* the deviations of every observation; more observations will tend to translate into larger scores (which implies worse fit)."
      ],
      "metadata": {
        "id": "6_VVyrXlQitP"
      }
    }
  ]
}